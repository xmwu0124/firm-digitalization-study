# IO Structural Estimation - Technical Documentation

## üìñ Overview

This script implements a **dynamic discrete choice model** in the Industrial Organization (IO) tradition, estimating the structural parameters governing firms' digital technology adoption decisions.

---

## üéØ Model Specification

### Decision Problem

Firms face a **dynamic discrete choice**:
- **Action**: Adopt digital technology (a=1) or wait (a=0)
- **Timing**: Each period, non-adopters decide whether to adopt
- **Irreversibility**: Once adopted, cannot revert
- **Payoffs**: Adoption generates persistent benefits but has fixed costs

### State Variables

**s_t = (size_t, comp_t, tech_t, adopted_t)**

- `size_t`: Log firm size (employment)
- `comp_t`: Industry competition index
- `tech_t`: Tech industry indicator (0/1)
- `adopted_t`: Already adopted indicator (0/1)

### Flow Payoffs

**u(s_t, a_t) = œÄ(s_t, a_t) - FC(a_t)**

**Operating Profit** (if adopted):
```
œÄ(s,1) = Œ±‚ÇÅ¬∑size + Œ±‚ÇÇ¬∑(-comp) + Œ±‚ÇÉ¬∑tech
```

**Costs**:
- Fixed adoption cost: `FC_adopt` (one-time, paid at adoption)
- Maintenance cost: `FC_maintain` (per-period, if technology active)

### Bellman Equation

**V(s) = E_Œµ [max_a {u(s,a) + Œµ(a) + Œ≤¬∑E[V(s')|s,a]}]**

Where:
- `Œ≤`: Discount factor
- `Œµ(a)`: Type I Extreme Value shocks (scale parameter œÉ)
- `s' ~ F(s'|s,a)`: State transitions

### State Transitions

**Size evolution** (AR(1) process):
```
log(size_{t+1}) = Œ≥¬∑log(size_t) + Œ∑_t,  Œ∑_t ~ N(0, œÉ¬≤)
```

**Competition and industry**: Assumed fixed (can be extended)

**Adoption status**:
```
adopted_{t+1} = max(adopted_t, a_t)
```

---

## üî¨ Estimation Strategy

### Step 1: Discretize State Space

Create finite grids:
- Size: 8 points on [log(size_min), log(size_max)]
- Competition: 5 points on [0, 1]
- Tech: {0, 1}
- Adopted: {0, 1}

**Total states**: 8 √ó 5 √ó 2 √ó 2 = 160 states

### Step 2: Build Transition Matrix

Compute `P[s,a,s']` for all (state, action, next state) triples:
```python
P = build_transition_matrix(state_space, params)
# Shape: (160, 2, 160)
```

### Step 3: Solve Dynamic Program

Use **value function iteration**:

```python
# Initialize
V = zeros(n_states)

# Iterate until convergence
while not converged:
    # Bellman operator
    EV = P @ V  # Expected continuation value
    Q = flow_payoffs + Œ≤ * EV  # Total value
    V_new = œÉ * log(sum(exp(Q/œÉ)))  # Logit inclusive value
    
    # Check convergence
    converged = ||V_new - V|| < tol
    V = V_new

# Extract policy
policy[s,a] = exp(Q[s,a]/œÉ) / sum_a' exp(Q[s,a']/œÉ)
```

This gives **choice probabilities** for each state.

### Step 4: Maximum Likelihood Estimation

**Likelihood function**:
```
L(Œ∏ | data) = ‚àè_{i,t} Pr(a_it | s_it; Œ∏)
```

Where `Pr(a|s;Œ∏)` comes from solving the DP with parameters `Œ∏`.

**Objective**:
```
Œ∏ÃÇ = argmax_Œ∏ log L(Œ∏ | data)
```

**Parameters to estimate**:
```
Œ∏ = (Œ±‚ÇÅ, Œ±‚ÇÇ, Œ±‚ÇÉ, FC_adopt, FC_maintain, Œ≤, Œ¥, Œ≥, œÉ_Œ∑, œÉ_Œµ)
```

### Step 5: Standard Errors

Compute via **numerical Hessian**:
```
SE(Œ∏ÃÇ) = sqrt(diag(H(Œ∏ÃÇ)‚Åª¬π))
```

Where `H` is the Hessian of the log-likelihood.

---

## üíª Implementation Details

### JAX Features Used

‚úÖ **JIT compilation**: All core functions decorated with `@jit`
```python
@jit
def bellman_operator(V, P, flow_payoffs, params):
    ...
```

‚úÖ **Vectorized operations**: Use `jnp.einsum` for tensor contractions
```python
EV = jnp.einsum('ijk,k->ij', P, V)
```

‚úÖ **Automatic differentiation**: Can compute gradients if needed
```python
grad_fn = jax.grad(neg_log_likelihood)
```

‚úÖ **64-bit precision**: Essential for numerical stability
```python
jax.config.update("jax_enable_x64", True)
```

### Optimization

**Method**: L-BFGS-B (quasi-Newton with bounds)

**Why**:
- Handles box constraints naturally
- Fast convergence for smooth objectives
- Low memory requirements

**Bounds**:
```python
bounds = [
    (0.0, 2.0),    # Œ±‚ÇÅ (size benefit)
    (0.0, 2.0),    # Œ±‚ÇÇ (competition benefit)
    ...
    (0.9, 0.99),   # Œ≤ (discount factor)
    ...
]
```

### Computational Tricks

1. **Precompute flow payoffs**: Done once per parameter vector
   ```python
   flow_payoffs = compute_flow_payoffs(state_space, params)
   ```

2. **Cache transition matrix**: Only depends on size dynamics
   ```python
   P = build_transition_matrix(state_space, params)
   # Reuse across likelihood evaluations
   ```

3. **Logsumexp for stability**: Avoid numerical overflow
   ```python
   V = scale * logsumexp(Q / scale, axis=1)
   ```

---

## üìä Output Interpretation

### Parameter Estimates

**Example output**:
```
Parameter Estimates:
------------------------------------------------------------
  alpha_size (benefit of size)          :   0.4523  (SE: 0.0821)
  alpha_comp (benefit of low comp)      :   0.2187  (SE: 0.0654)
  alpha_tech (tech industry premium)    :   0.6742  (SE: 0.1103)
  fc_adopt (fixed cost adoption)        :   2.1456  (SE: 0.3210)
  fc_maintain (maintenance cost)        :   0.1834  (SE: 0.0432)
  beta (discount factor)                :   0.9512  (SE: 0.0089)
  ...
```

**Interpretation**:
- `Œ±‚ÇÅ = 0.45`: 1% larger firm ‚Üí 0.45% higher flow payoff if adopted
- `Œ±‚ÇÉ = 0.67`: Tech firms get 67% higher payoff from adoption
- `FC_adopt = 2.15`: Fixed cost equivalent to 2.15 units of profit
- `Œ≤ = 0.95`: Firms discount future at ~5% per period

### Counterfactual: Adoption Subsidy

**Policy**: Reduce fixed cost by 1.0 unit

**Results**:
```
Baseline adoption rate: 0.423
With subsidy: 0.518
Increase: 0.095 (22.5%)
```

**Interpretation**: Subsidy of 1.0 increases adoption by 9.5 percentage points (22% relative increase)

---

## üî¨ Methodological Notes

### Comparison to Reduced-Form Methods

| Feature | Reduced-Form (DiD) | Structural (IO) |
|---------|-------------------|-----------------|
| **Causal effect** | ‚úÖ Average treatment effect | ‚úÖ Full distribution of effects |
| **Mechanisms** | ‚ùå Black box | ‚úÖ Explicit payoffs & dynamics |
| **Counterfactuals** | ‚ùå Limited | ‚úÖ Any policy scenario |
| **Data requirements** | Low | High |
| **Computation** | Fast | Slow (DP solving) |
| **Assumptions** | Parallel trends | Full model specification |

### When to Use Structural Estimation

**Use when**:
- ‚úÖ Need to evaluate untested policies
- ‚úÖ Want to understand mechanisms
- ‚úÖ Have rich panel data
- ‚úÖ Can credibly specify model

**Don't use when**:
- ‚ùå Just want causal effect (use DiD)
- ‚ùå Model is mis-specified
- ‚ùå Computation is infeasible
- ‚ùå Data is too sparse

### Extensions

This model can be extended to include:

1. **Heterogeneous effects**:
   ```python
   # Add firm-specific random coefficients
   Œ±‚ÇÅ·µ¢ = Œ±‚ÇÅ + ŒΩ·µ¢,  ŒΩ·µ¢ ~ N(0, œÉ_Œ±¬≤)
   ```

2. **Strategic interactions**:
   ```python
   # Payoff depends on rivals' adoption
   œÄ(s, a, a‚Çã·µ¢) = Œ±‚ÇÅ¬∑size + Œ±‚ÇÑ¬∑(Œ£ a‚Çã·µ¢)
   ```

3. **Entry/exit**:
   ```python
   # Additional actions: exit market
   a ‚àà {0 (wait), 1 (adopt), 2 (exit)}
   ```

4. **Unobserved state variables**:
   ```python
   # Add permanent unobserved type
   s = (size, comp, tech, adopted, type)
   ```

---

## üöÄ Running the Code

### Quick Start

```bash
# Make sure you have JAX installed
pip install jax jaxlib

# Run estimation
python 04_capital_estimation/io_structural_model.py
```

### Expected Runtime

- State space construction: <1 second
- Transition matrix: ~5 seconds
- DP solving (per iteration): ~10 seconds
- Full estimation: ~10-20 minutes (depends on optimization)

### Memory Requirements

- ~50 MB for 160-state model
- Scales as O(n_states¬≤) due to transition matrix

### Troubleshooting

**"DP not converging"**:
- Increase `max_iter` in `solve_dynamic_program`
- Decrease discount factor Œ≤ slightly
- Check flow payoffs for NaN values

**"Optimization slow"**:
- Reduce state space size (fewer grid points)
- Use better starting values
- Try different optimizer (e.g., Nelder-Mead)

**"Numerical overflow"**:
- Ensure using 64-bit precision
- Use `logsumexp` instead of manual exp/log
- Scale payoffs to reasonable magnitude

---

## üìö References

### Key Papers

**Dynamic discrete choice**:
- Rust, J. (1987). "Optimal replacement of GMC bus engines: An empirical model of Harold Zurcher." *Econometrica*, 55(5), 999-1033.

**Conditional choice probabilities**:
- Hotz, V. J., & Miller, R. A. (1993). "Conditional choice probabilities and the estimation of dynamic models." *Review of Economic Studies*, 60(3), 497-529.

**Sequential estimation**:
- Aguirregabiria, V., & Mira, P. (2007). "Sequential estimation of dynamic discrete games." *Econometrica*, 75(1), 1-53.

**Two-step estimation**:
- Arcidiacono, P., & Miller, R. A. (2011). "Conditional choice probability estimation of dynamic discrete choice models with unobserved heterogeneity." *Econometrica*, 79(6), 1823-1867.

### Software

- **JAX**: [https://github.com/google/jax](https://github.com/google/jax)
- **QuantEcon**: [https://quantecon.org/](https://quantecon.org/) - Similar DP examples in Python

---

## ‚úÖ Validation Checklist

Before trusting results:

- [ ] DP converges to fixed point
- [ ] Choice probabilities sum to 1
- [ ] Likelihood is finite and improving
- [ ] Parameter estimates are economically reasonable
- [ ] Standard errors are not too large
- [ ] Counterfactuals make sense
- [ ] Robustness to starting values
- [ ] Robustness to state space discretization

---

## üéì Teaching Notes

This script is designed to be pedagogical:

1. **Clear structure**: Each step (payoffs ‚Üí transitions ‚Üí DP ‚Üí likelihood ‚Üí estimation) is separate

2. **Extensive comments**: Explains *why* not just *what*

3. **Named tuples**: `ModelParams` and `StateSpace` make code readable

4. **Logging**: Tracks progress and aids debugging

5. **Modular**: Easy to swap out components (e.g., different transition spec)

**Use in class**:
- Walk through model specification on board
- Show DP solution convergence
- Discuss identification (which parameters come from what variation)
- Compare structural vs reduced-form results

---

**Questions?** See main README.md or contact the research team.
